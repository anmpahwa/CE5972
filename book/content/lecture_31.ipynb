{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 31: Threshold Accepting\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Much like the Tabu Search algorithm, the Threshold Accepting algorithm is designed to search for high-quality solutions in complex search space while avoiding local optimal traps. However, unlike the Tabu Search, this algorithm does so with fewer degrees of freedom (input parameters). It starts by initialising the current solution – $s$, and the best solution – $s^*$, from the given initial solution – $s_o$. The algorithm then iterates searching the solution space for better solutions until it has achieved threshold level of solution quality or computation effort. In each such iteration, the algorithm generates a random new solution by applying a defined set of transformations to the current solution defined by the neighbourhood – $N(s)$. Notably, unlike any of the previously discussed algorithms, the Threshold Accepting algorithm accepts this new solution as the current solution even if it is somewhat worse than the current solution. Specifically, if the difference in objective function values of the new and the current solution is less than a predefined threshold – $Δ (Δ>0)$, then the algorithm sets the current solution to this new solution. However, the algorithm updates the best solution only if the new solution is better than the best. Finally, upon convergence, the Threshold Accepting algorithm returns the best solution.\n",
    "\n",
    "The Threshold Accepting algorithm balances solution diversification (exploration) by accepting certain inferior solutions as the current solution, and solution intensification (exploitation) by only accepting better solutions as the best solution. And while the Tabu Search achieves this balance by maintaining a dedicated list of “tabooed” and “accepted” solutions, the Threshold Accepting algorithm does so with just one parameter – $Δ$. This allows for fast implementation with low computational effort due to minimal fine-tuning and memory requirements. Nonetheless, if the threshold is set too high, then the algorithm will have a slow convergence (exploration bias). On the other hand, it the threshold is set too low, then the algorithm will get stuck on a local optimal (exploitation bias). Thus, with appropriately sized threshold, the algorithm can swiftly converge to high quality solutions, even for problems with complex multimodal solution landscape.\n",
    "\n",
    "Despite its simplicity, the Threshold Accepting algorithm has found limited use for optimisation in Transportation Engineering. Beyond transportation systems however, the algoirthm has been deployed succesfully to address job scheduling and timetable optimisation problems, potentially inspiring its use in ITS for optimising public transit schedule, time table, and dispatch.\n",
    "\n",
    "---\n",
    "\n",
    "## Pseudo Code\n",
    "\n",
    "1. **Procedure** $\\text{TA}(s_o, (N, \\Delta))$\n",
    "2. $s ← s_o$ &emsp;<small>// initialise current solution $s$ as the initial solution $s_o$</small>\n",
    "3. $s^* ← s$ &emsp;<small>// initialise best solution $s^*$ as the current solution</small>\n",
    "4. **while** $!\\text{converged}$ **do** &emsp;<small>// repeat until converged</small>\n",
    "5. &emsp;$s' {R \\atop ←} N(s)$ &emsp;<small>// generate new random solution from neighborhood $N$ of the current solution</small>\n",
    "6. &emsp;$\\delta ← f(s') - f(s)$ &emsp;<small>// calculate the difference in objective values</small>\n",
    "7. &emsp;**if** $\\delta < \\Delta$ **then** &emsp;<small>// if the new solution is within threshold $\\Delta$ of the current solution</small>\n",
    "8. &emsp;&emsp;$s ← s'$ &emsp;<small>// update the current solution to the new solution</small>\n",
    "9. &emsp;**end if**\n",
    "10. &emsp;**if** $f(s) < f(s^*)$ **then** &emsp;<small>// if the current solution is better than the best solution</small>\n",
    "11. &emsp;&emsp;$s^* ← s$ &emsp;<small>// update the best solution to the current solution</small>\n",
    "12. &emsp;**end if**\n",
    "13. **end while**\n",
    "14. **return** $s^*$ &emsp;<small>// return the best solution</small>\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ta(s_o, N, D, n=100, t=1e-5):\n",
    "    \"\"\"\n",
    "    Threshold Accepting Algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    - s_o: Initial solution\n",
    "    - N: Neighborhood function\n",
    "    - Delta: Threshold for acceptance\n",
    "    - n: Number of iterations\n",
    "    - t: Convergence threshold\n",
    "    \n",
    "    Returns:\n",
    "    - Best solution found in each iteration\n",
    "    \"\"\"\n",
    "    s = s_o     # Current solution\n",
    "    s_b = s     # Best solution found\n",
    "    S = [s_b]   # Track best solutions over iterations\n",
    "    \n",
    "    i = 1\n",
    "    e = float('inf')\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        s_n = N(s)                      # Generate a random neighbor\n",
    "        d   = f(s_n) - f(s)             # Compute objective function difference\n",
    "        \n",
    "        if d < D:                       # Accept if within threshold\n",
    "            s = s_n\n",
    "        \n",
    "        if f(s) < f(s_b):              # Update best solution if improved\n",
    "            e = f(s_b) - f(s)\n",
    "            s_b = s\n",
    "        \n",
    "        S.append(s_b)                  # Store the best solution at each iteration\n",
    "        \n",
    "        i += 1\n",
    "        if i >= n or e <= t:           # Convergence condition\n",
    "            converged = True\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
